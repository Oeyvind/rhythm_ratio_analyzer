* maybe need to write a variant on the Markov class where we just give each event a value 
  - for example for downbeat weight, for each event: how heavy it is
  - for other parameters: 
    amplitude (or velocity)
    pitch class (how much does it conform to a pitch class)
    melodic scale (how much does it conform to a scale)
    - some of these might need separate analysis modules to give the proper values
    - for example the downbeat weight needs a separate analysis (maybe based on the autocorr analysis)


---
* audio input to midi trigger conversion with Mountains and lakes

* markovian player could need a "sync to pulse" option, where any rhythm pattern leading to contant offbeats will be "guided" back to downbeats

* markovian generator will most likely not produce compound/compoite patterns? 
  - e.g. clave and subgroupings
    - 3,3,2
    - 3,2,3,2,3,2,2 (5)
    - 3,2,2,3,2,2,4 (7)
    - ... or will it? ... if biased towards a sync to pulse/downbeat?
    - may need a "subgrouping preference" to maintain e.g. groups of 7

* the rhythm generator (markovian and variants) implemented in Python instead of Csound
  - easier to handle complex relationships and patterns
  - Csound player should be milliseconds based (kr clock, millisecond lookup for next event). As simple as possible.
    - any latency in OSC communication can be remedied (?) as event rate is relatively low
    - ask for next event data immediately after dispersing an event
    - can also ask for several next events, then discard unused events if external conditions change

* analyze several overlapping windows
  - preference rule to maintain assumption from previous window
  - novelty indicator, should not need to be placed on analysis window boundaries
  - how to maintain the whole history?
    - rewrite older ratios?
    - keep reference to new interpretation (tempo/pulse/triggerseq/ratio-subdiv)
  - save complete (compound) ratios_commondiv for whole sequence, all recordings. Personal corpus.
  - in generator: may ask for events within same tempo/complexity segment(s) of whole corpus

* rhythm analyzer still makes some mistakes
  - generate definitive test set of rhythms that it must recognize

* vst: 
  - clear should slear display also
  - auto record: 
    - enable record so that it starts recording on the first event received
    - stop recording N secs after last event (can also be manually triggered)
    - restart recording (continue) on next event after "pause"
      - when merging recording segments
        - last event from previous = first event from next phrase

