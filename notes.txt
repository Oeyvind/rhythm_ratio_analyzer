
# Reconciliation
# if no match:
    - with synthetic test sequences: 
      - double check if the time series would be perceptually interpretable as the duration pattern
      - see how we can massage the algorithm to interpret it correctly
    - with real data:
      - perhaps there was a tempo or time signature change during the analysed phrase
      - see if we can break up the phrase to find the switch point:
          - run ratio analyzer on subsequences, adding one event at a time 
          - look for the point where we get a significantly higer deviation
          - divide the phrase there, analyze first and second half independently 
            (not reconcile across this phrase border)
    - BUT: the best and simplest approach is if we find no reconciliation match, do not reconciliate
      - that is, keep the analyses of the two phrases as they are
      - if we encountered a tempo change, the first phrase is from the old tempo, the second in the new tempo
        - in this case, keeping them as they are would be good
        - any uncertainties regarding the second phrase will be solve in the next iteration (next new phrase)
      - possible problem: if the tempo shift does not occur on an analysis boundary (likely)
        - that is, we divide the input into arbutrary chunks that most likely does not correspond to played phrases
        - might need to investigate the phrase(s) to find the location of the tempo shift
          - use method outlined above (ratio approximation on incremental subsequence) to find the point




* Compare scores for these examples
0 1 1 0.3 1 0.2 0.3 0.99 (good?)
1 1 1 1   1 1   1   1 (not so good)

timedata: [0.   0.56 0.81 1.06 1.57 2.11 2.51 2.67 3.17 3.42 3.68]
ticktempo 22.277264744207127
[[12.   12.    0.04  0.56  0.54]
 [ 6.   12.   -0.04  0.25  0.54]
 [ 6.   12.   -0.02  0.26  0.54]
 [12.   12.   -0.06  0.51  0.54]
 [12.   12.    0.    0.54  0.54]
 [ 9.   12.   -0.01  0.4   0.54]
 [ 4.   12.   -0.04  0.16  0.54]
 [12.   12.   -0.07  0.5   0.54]
 [ 6.   12.   -0.02  0.26  0.54]
 [ 6.   12.   -0.02  0.26  0.54]]
** We should see through the metric structure and find that 9+4 is not likely

timedata: [0.   0.54 0.81 1.08 1.58 2.02 2.17 2.44 2.69]
ticktempo 14.90075410208799
[[ 8.   12.    0.01  0.54  0.81]
 [ 4.   12.   -0.01  0.26  0.81]
 [ 4.   12.    0.    0.27  0.81]
 [ 8.   12.   -0.04  0.5   0.81]
 [ 6.   12.    0.05  0.44  0.81]
 [ 2.   12.    0.01  0.14  0.81]
 [ 4.   12.    0.01  0.28  0.81]
 [ 4.   12.   -0.03  0.25  0.81]]
ratios best:
[0.67 0.33 0.33 0.67 0.5  0.17 0.33 0.33]
** We should look at the duration pattern 8,4,4,8... and see that it is not a 12-subdiv rhythm
** Should be 1 0.5 0.5 1 0.75 0.25 0.5 0.5

* Notes on optimization
  - Fractions.div_limit is used a lot (ratio_to_each) and is expensive
  - array_equal is used a lot (evidence and find_duplicate_representations) and is expensive




* clean up Csound script
  - remove time series, ratios, deviation text fields
  - one nslider for last_recorded_time_value
  - remove "calc" and "rank"
  - can we get rid of line 212 pp ?
    ; receive and process rhythm ratio data from Python
  - clean up instr 109 according to 4) and 5) above
















---
old notes:
---
* audio input to midi trigger conversion with Mountains and lakes

* markovian player could need a "sync to pulse" option, where any rhythm pattern leading to contant offbeats will be "guided" back to downbeats

* markovian generator will most likely not produce compound/composite patterns? 
  - e.g. clave and subgroupings
    - 3,3,2
    - 3,2,3,2,3,2,2 (5)
    - 3,2,2,3,2,2,4 (7)
    - ... or will it? ... if biased towards a sync to pulse/downbeat?
    - may need a "subgrouping preference" to maintain e.g. groups of 7

* the rhythm generator (markovian and variants) implemented in Python instead of Csound
  - easier to handle complex relationships and patterns
  - Csound player should be milliseconds based (kr clock, millisecond lookup for next event). As simple as possible.
    - any latency in OSC communication can be remedied (?) as event rate is relatively low
    - ask for next event data immediately after dispersing an event
    - can also ask for several next events, then discard unused events if external conditions change

* analyze several overlapping windows
  - preference rule to maintain assumption from previous window
  - novelty indicator, should not need to be placed on analysis window boundaries
  - how to maintain the whole history?
    - rewrite older ratios?
    - keep reference to new interpretation (tempo/pulse/triggerseq/ratio-subdiv)
  - save complete (compound) ratios_commondiv for whole sequence, all recordings. Personal corpus.
  - in generator: may ask for events within same tempo/complexity segment(s) of whole corpus

* rhythm analyzer still makes some mistakes
  - generate definitive test set of rhythms that it must recognize

* vst: 
  - clear should slear display also
  - auto record: 
    - enable record so that it starts recording on the first event received
    - stop recording N secs after last event (can also be manually triggered)
    - restart recording (continue) on next event after "pause"
      - when merging recording segments
        - last event from previous = first event from next phrase

